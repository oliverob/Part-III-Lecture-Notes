\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{braket}
\title{Quantum Information Theory}
\author{oliverobrien111 }
\date{July 2021}

\begin{document}

\maketitle

\section{Shannon entropy}
Alternative definition is using the surprisal $\gamma(x) = -\log p(x)$ which measures how likely an event is. The Shannon entropy is the expected value of the surprisal. A good way of thinking about it is the information gained on average when you learn the value of $X$.\\\\
For a string chosen from the binary alphabet the number of distinct strings of length $n$ is the binomial coefficient ${n \choose np}$ which is approximated by Strilings approximation $\log n! = n\log n - n$ to give
$$
\log {n \choose np} \approx nH(p)
$$
for the entropy function:
\begin{equation}
    H(p) = -p\log p - (1-p) \log (1-p)
\end{equation}
Therefore, the strings can be specified by a block code of $2^{nH(p)}$ letters. As $H(p) \leq 1$, the block code is shorter than the message. This reflects the fact that for large $n$ the chance of an unlikely string like 1111111111... becomes very small, so can be left out of the block code. This generalises to $n$ letters to give Shannon entropy:
\begin{equation}
    H(X) = \sum_x -p(x)\log p(x)
\end{equation}
\subsection{Properties of H}
$$
H(X) = H(\{p(x)\}) = H(p_x)
$$
Permutation invariant. If you have a $\pi$ permutation of $X$ then:
$$
H(p_X \cdot \pi) = H(p_X)
= -\sum_{x\in J} p(\pi(x))\log p(\pi(x)) = -\sum_{x\in J} p(x) \log p(x)
$$
$H(X) \geq 0$
\subsection{Formal Proof}
A typical sequence $\bm u$ is defined as one which for which the probability of occurrence satisfies:
\begin{equation}
2^{-n(H(X)+\epsilon}\leq p(\bm u) \leq2^{-n(H(X)-\epsilon}
\label{typicalsequence}
\end{equation}
Typical sequence theorem states that the probability of getting any typical sequence can be made arbitrarily close to 1 for large enough $n$. Let $T_{\epsilon}^{(n)}$ be the set of typical sequences, then the probability of getting any typical sequence is bounded by:
$$ 2^{-n(H(X)+\epsilon}|T_{\epsilon}^{(n)}| \leq
\sum_{\bm u \in T_{\epsilon}^{(n)}} p(\bm u) \leq 1
$$
using the left hand inequality of \ref{typicalsequence}. Therefore, $|T_{\epsilon}^{(n)}| \rightarrow 2^{n H(X)}$ as $\epsilon \rightarrow 0$.\\\\
Pick $\epsilon$ such that $R> H(X) + \epsilon$. Break set of possible sequences into typical set and its complement $A^{n}_{\epsilon}$. Encode any value in $A^{n}_{\epsilon}$ to flag bit $0$ and assign a codeword of length $n R$ to elements in $T_{\epsilon}^{(n)}$ (which is possible as  $|T_{\epsilon}^{(n)}| \leq 2^{n(H(X)+\epsilon} < 2^{n R}$). Probability of failure is:
\begin{equation}
    \sum_{\bm u \in A^{n}_{\epsilon}}p(\bm u)
\end{equation}
which by typical sequence theorem can be made arbitrarily small (as the probability of being in  $T_{\epsilon}^{(n)}$ tends to 1).
\subsubsection{Converse}
Pick a subset of the typical set $S^n$ with $|S^n| = 2^{n R}$ with $R< H$. The probability of a sequence being in $S^n$ is:
$$
P(S^n) = \sum_{\bm u} p(\bm u) = 2^{n R}2^{-n H(X)}
$$
($p(\bm u) = 2^{-n H(X)}$ in limit as $n \rightarrow \infty$). As $H(X) - R  > 0$, this tends to $0$ as $n$ tends to infinity.\\\\
Intuitively it doesn't work as the number of sequences we missed grows exponentially as $n$ heads to infinity.\\\\
\textbf{Joint Entropy}:
\begin{equation}
    H(X,Y) = - \sum_{\bm x, \bm y} p(x,y) \log p(x,y)
\end{equation}
$$
H(X,Y)=H(X) + H(Y)
$$
\textbf{Conditional Entropy} (imagine X are the bits received over a noisy channel so this is the entropy of the source Y given the data received):
\begin{equation}
    H(Y|X) = \sum_{\bm x} p(x)H(Y|X=x) = \sum_{\bm x \bm y} p(x)p(y|x)\log p(y|x)
\end{equation}
After every letter is received a new optimal code can be found that will specify the remaining string with $H(Y|X)$ bits per letter. Therefore, \textbf{chain rule}
\begin{equation}
    H(X,Y) = H(Y|X)+H(X)
\end{equation}
\textbf{Relative Entropy} (defines a sort of distance between two probability distributions but is not a metric as not symmetric and does not satisfy triangle inequality):
\begin{equation}
    D(p||q) = \sum_{\bm x} p(x) \frac{p(x)}{q(x)}
\end{equation}
only 0 for $p = q$. The above is only well-defined if $p << q$ (meaning that $q(x) =0 \Rightarrow p(x) = 0$).\\\\
\textbf{Proof of Gibbs inequality}
$$
A  = \{ x \in J, p(x) > 0 \}
$$
$$
D(p||q) = \sum_{x \in A} p(x) \log \frac{p(x)}{q(x)} = -\sum_{x \in A} p(x) \log \frac{q(x)}{p(x)}
$$
Define a random variable to take values $\log \frac{p(x)}{q(x)}$ with probablity $p(x)$ then.
$$
-D(p||q) = \mathbb{E}_p(\log \frac{q(X)}{p(X)})
$$
using jensens inequality
$$
-D(p||q) \leq \log \mathbb{E}_p( \frac{q(X)}{p(X)}) = \log \sum_{A} p(x) \frac{q(X)}{p(X)} = \log \sum_A q(x) \leq \log \sum_{J} q(x) = 0
$$
so
$$
D(p||q) \geq 0
$$
\\ \textbf{Mutual information}:
\begin{equation}
    I(X;Y) = H(X) + H(Y) - H(X,Y)
\end{equation}
If you were to fill out a venn diagram with overlapping circles $H(X)$ and $H(Y)$ the union would be $H(X,Y)$, the intersection would be $I(X,Y)$ and the remainder of the circle $H(X)$ would be $H(X|Y)$ as once you are given one of the values there is no longer any entropy coming from its circle.\\\\
Neat result. As $D(p||q) \geq 0$ and given $q(x) = \frac{1}{|J|}$ for alphabet $J$,
$$
D(p||q) = \sum p(x) \log \frac{p(x)}{\frac{1}{|J|}} = - H(X) + \sum p(x) \log |J|
$$
$$
H(X) \leq \log |J|
$$
\textbf{Jensen's Inequality:} (for concave functions)
\begin{equation}
    \mathbb{E}(f(X)) \leq f(\mathbb{E}(X))
\end{equation}
Need to learn what concavity really means as used lots in quantum part of course. Important to know that $H(X)$ is concave.\\
\textbf{Subadditivity}
Prove this with $D(p||q) \geq 0$ and jensens inequality. Do it on example sheet 1.
\begin{equation}
    H(X,Y) \geq H(X) + H(Y)
\end{equation}
5.28 of chapter 5 of Caltech I don't understand\\\\
Can use relative entropy as a parent quantity to get all the types of entropy from above. But only if we lift the restriction of the distributions having total probablity 1. For example if we take $q(x) = 1 \forall x$ then $D(P||Q) = - H(X)$. Also, $I(X:Y) = D(p(x,y)||p(x)p(y))$ and $H(Y|X) = D(p(x,y)||p(x))$. Prove and check these on example sheet.
\subsection{Shannon's Noisy Channel Theorem}
For certain codewords, their images after applying the channel map will represent disjoint subsets in the asymptotic limit. The typical number of sequences that will be received is $|T_n| \approx 2^{nH(Y|X)}$, whereas the size of the range is  $2^{nH(Y)}$, so the maximum achievable rate (number of bits communicated per use of channel) is $\frac{2^{nH(Y)}}{2^{nH(Y|X)}} = 2^{nI(Y;X)}$.\\\\
If a message of length $n$ is sent along a channel with an error rate of $p$. Then roughly $np$ bits will flip, leading to $2^{nH(p)}$ typical output strings (it would be $2^{np}$ strings but we have to account for the encoding reducing the number of strings). In order for this input to be accurately distinguished from any other this "sphere" of possibilities must be distinct from the rest. Therefore, there must be at least $2^{nR}2^{nH(p)}$ possible output strings. Therefore, $R \leq 1 - H(p) = C$.\\\\
Can be shown that even picking random codewords gives the optimal rate in the asymptotic limit. If we adopt the decoding method of drawing a "Hamming sphere" of radius $2^{n(H(p)+\delta}$ around the received string and looking for a codeword within this radius. We would typically expect their to be at least one or our assumption about the error in the channel is wrong/we need a bigger delta. The chance of there being two can be calculated as the fraction of space occupied by the s"sphere" is:
$$
\frac{2^{n(H(p)+\delta)}}{2^n} = 2^{-n(C-\delta)}
$$
so the chance of one of the $2{nR}$ codewords lieing there is:
$$
2^{-n(C-R-\delta)}
$$
As $\delta$ can be as small as we like, we can pick $R$ as close as we want to $C$ and this will still vanish asymptotically. APPARENTLY THE AVERAGE IS TAKEN HERE BUT I DON'T SEE WHERE.\\\\
\subsection{Shannon's Noisy Channel Coding Theorem - lectures}
\subsubsection{Discrete Memoryless Channel (DMC)}
Action of each successive uses of $\mathfrak{N}$ is identical and independent to the previous use/the noise affecting each successive inputs in uncorrelated. 
$$
p(u^{(n)}|x^{(n)}) = \sum_{i=1}^n p(u_i|x_i)
$$
Might as well restrict to only considering a single use of the channel. Can write channel matrix as $p_{ij} =p(y_i|x_i)$. The channel matrix is symmetric if the rows are permutations of each other.
\subsubsection{Example - Memoryless Binary Symmetric Channel  (m.b.s.c)}
$$J_x = \{0,1\} = J_y$$
Flips the bit with probability $p$. So we need an error-correcting code, e.g. the repetition code using three bits at once.\\\\
\textbf{Rate}: The encoding decoding pair is said to have a rate R if $|M|$ (number of possible messages) = $2^{nR}$ for a given number of channel uses $n$.\\\\
Maximum probability of error corresponding to $C_n$:
$$
p^{(n)}_{err}(C_n) = P(\mathfrak{D}_n(Y^{(n)}) \neq m | X^{(n)} = \epsilon_n(m))
$$
\textbf{Achievable rate}: A $R \in \mathbb{R}$ is said to be an achievable rate if there exists a sequence of codes ($(C_n)_n$) of rate $R$ s.t. $p^{(n)}_{err} \rightarrow 0$ as $n\rightarrow \infty$.\\
\textbf{Channel Capacity}: Maximum rate of reliable transmission of information $C(\mathfrak{N}) = \sup \{R: \textrm{R is an achievable rate}\}$\\\\
Shannon's Theorem says that $C(\mathfrak{N}) = max_{\{p(x)\}} I(X:Y)$. Not going to do this proof as it is not very connected to the quantum proof.\\\\
For m.b.s.c
$$
I(X:Y) = H(Y) - H(Y|X) = H(Y) - (-(1-p)\log(1-p) - p\log p) = H(Y) - h(p) \leq \log |J_Y| - h(p) = 1 - h(p)
$$
Does there exist some distribution $\{p(x)\}$ for which $H(Y) = 1$ because if there is then this bound is saturated.
$$
H(Y) = - \sum p(y) \log p(y)
$$
$$
p(y) = \sum_x p(x,y) = \sum_x p(x)p(y|x)
$$
So look for $p(x)$ that makes $p(y)$ equiprobable. Try $p(x) = \frac{1}{2}$, and this indeed gives $H(Y) = 1$. Therefore $C(\mathfrak{N}) = 1-h(p)$. (I am confused about this as the H(Y) only reaches its maximum for $p=1/2$ when $h(p)$ is also 1 so surely this doesn't work? ask in office hours).\\
\section{Quantum}
Can associate many ensembles with the same state. You can use any $\{p_i, \ket{\psi_i}\}$ as long as $p_i \geq 0$, $\sum p_i = 1$ and $\bra{\psi_i}\ket{\psi_i} = 1$. You can find an infinite number of these ensembles that give the same spectral decomposition (are identical) as the $\ket{\psi_i}$ need not even by orthogonal and can basically be anything as long as they have norm 1. e.g. $\rho = \frac{I}{d} = \sum_j \frac{1}{d} \ket{e_j}\bra{e_j} = \sum_k \frac{1}{d} \ket{\psi_k}\bra{\psi_k}$ so ensembles $\{\frac{1}{d}, \ket{e_j}\}$ and $\{\frac{1}{d}, \ket{\psi_k}\}$ are both equally valid.\\\\
Expectation of observable A in state $\rho$: $<A> = <A>_{\rho} = Tr(A\rho)$ which is a positive linear functional.\\\\
System of interest to us in the course is often a subsystem S of a composite system SE. The density matrix formalism provides a description of states of subsystems. Consider a comp. system AB then the underlying hilbert space is $\mathcal{H}_A \otimes \mathcal{H}_B$. If AB is in the state $\rho_{AB} \in \mathfrak{D}(\mathcal{H}_A \otimes \mathcal{H}_B$)$ then state A is given by the reduces state: $\rho_A = Tr_B \rho_{AB}. Consider orthonomal basis $\{ \ket{i_A} \}$ in $\mathcal{H}_A$ and $\{ \ket{\alpha_B} \}$ in $\mathcal{H}_B$ then we have $\{ \ket{i_A} \otimes \ket{\alpha_B} \}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$. Can always write $A = \sum a_{ij} \ket{i}\bra{j}$ with $a_{ij} = \bra{i}A\ket{j}$.
$$
\rho_{AB} =\sum_{i,j =1}^{d_A} \sum_{\alpha,\beta=1}^{d_B} r_{i\alpha, j\beta}\ket{i_A}\ket{\alpha_B}\bra{j_A}\bra{\beta_B}
$$
$$
\rho_A = Tr_B \rho_AB = Tr_B (\sum_{i,j =1}^{d_A} \sum_{\alpha,\beta=1}^{d_B} r_{i\alpha, j\beta}\ket{i_A}\bra{j_A}\otimes\ket{\alpha_B}\bra{\beta_B}) = \sum_{i,j=1}^{d_A} \sum_{\alpha=1}^{d_B} r_{i\alpha, j\alpha \ket{i_A}\bra{j_A}
$$
Consider an observable $M_{AB} = M_A \otimes I_B$ then we claim that:
$$
<M_{AB}>_{\rho_{AB}} = Tr(M_{AB} \rho_{AB})
$$
Proof:
$$
<M_{AB} = Tr(M_{AB} \sum_{i,j =1}^{d_A} \sum_{\alpha,\beta=1}^{d_B} r_{i\alpha, j\beta}\ket{i_A}\bra{j_A}\otimes\ket{\alpha_B}\bra{\beta_B}) =\sum_{i,j =1}^{d_A} \sum_{\alpha=1}^{d_B}r_{i\alpha, j\alpha} Tr(M_A\ket{i}\bra{j} = Tr(M_A\rho_A)
$$
\textbf{Example}: Consider state of 2 qubits $\rho_{AB} = \ket{phi^+_{AB}}\bra{\phi^+_{AB}}$ with $\ket{phi^+_{AB}} = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11})$. Therefore, $\rho_A = Tr_B\rho_{AB} = \frac{I}{2}$ which is an example of when we know everything about the system but still have no information about A or B.\\\\
A pure state is known as a product state if it can be written: $\psi_{AB} = \ket{\psi_A} \otimes \ket{\psi_B}$ and if it cannot be written like this then it is called entangled.\\\\
A mixed state is a seperable state if it can be written as an ensemble with pure states: $\rho_{AB} = \sum_i p_i \omega_{A}^i \otimes \tau_B^i. Otherwise it is called an entangled state.\\\\
The four pure states in $\mathbb{C}^2 \otimes \mathbb{C}^2$ are called Bell states and EPR states.
\subsection{Schmidt decomposition}
Any state in space $\mathbm{H}_A \otimes \mathbm{H}_B $ can be described using coefficients of basis states of the form $\ket{i_A} \otimes \ket{i_B}$ where $\ket{i_A}$ for some set of basis eigenstates $\ket{i_A}$, $\ket{i_B}$. The schmidt rank is the number of positive Schmidt coefficents.\\\\
There always exists a set of orthonormal vectors $\{\ket{i_A}\}$ and $\{\ket{i_B}\}$ such that:
$$
\ket{\psi_{AB}} = \sum_{i=1}^{\kappa=min(d_a,d_b)} \lambda_i \ket{i_A}\ket{i_B}
$$
Proof:
$$
\psi_{AB} = \sum_{r,\alpha} a_{r\alpha} \ket{\gamma_A}\ket{\alpha_B}
$$
\textbf{Singular Value Decompisition (SVD)}: Need to know proof look up in notes\\
There exists unitaries U $d_A\times d_A$ and V $d_B \times d_B$ s.t $A = UDV$ with D a diagonal matrix $d_A \times d_B$ . Therefore,
$$
\alpha_{r,\alpha} = \sum_{i=1}^{d_A} \sum_{\beta=1}^{d_B} u_{\gamma i} d_{i \beta} u_{\beta \alpha}
$$
$$
\ket{\psi_{AB}} = \sum \sum d_{i\beta} (\sum u_{r i} \ket{r_A}) (\sum v_{\beta \alpha} \ket{\alpha_B})
$$
as $d_{i \beta} = \deta_{i \beta}d_{ii}$
$$
\ket{\psi_{AB}} = \sum_i d_{ii} (\ket{i_A}) (\ket{i_B}) = \sum_i \lambda_i (\ket{i_A}) (\ket{i_B}) 
$$
Now need to check these $\{\ket{i_A}\}$, $\{\ket{i_B}\}$ are an orthonormal basis. So need to check they are orthonormal and complete ($\sum^{min(d_A,d_B)}_i \ket{i_A}\bra{i_B} = 1$). To check completeness consider:
$$
\rho_{AB} =  \ket{\psi_{AB}} \bra{\psi_{AB}}
$$
$$
\rho_A =  = Tr_B \ket{\psi_{AB}} \bra{\psi_{AB}} = Tr_B (\sum_i \lambda_i \ket{i_A} \ket{i_B}) (\sum_j \lambda_j \ket{j_A} \ket{j_B}) = \sum_{ij} \lambda_i \lamdba_j \ket{i_A}\bra{j_A} \otimes Tr_B \ket{j_A} \bra{j_B} = \sum_i \lambda_i^2 \ket{i_A} \bra{i_A}
$$
This means that if AB is in a pure state $\ket{\psi_{AB}}$ then $\rho_A$ and $\rho_B$ have identical sets of non-zero eigenvalues. If $d_A >d_B$ then $\rho_A$ has set of eigenvalues $\{\lamdba_i^2\}^{min(d_A,d_B)}$ and the rest are zero.\\\\
Is the schmidt deompistion unique? No if the eginvalues are degenerate. As you can generate the schmidt decompistion by diagonlising $\rho_A$ and $\rho_B$ then matching eigenvectors of the same eigenvalues (which is non-unique if there are degenerate eigenstates.\\\\
The set of $\{\lambda_i\}$ are called Schmidt coefficents, and the set $\{\ket{i_A}\}$, $\{\ket{i_B}\}$ are the schmidt baseses, and $n(\psi_{AB})$ (the number of non-zero schmidt coefficents) is called the Schmidt rank. The schmidt rank is the simplest signature of entanglement as $\ket{\psi_{AB}}$ is entangled iff $n(\psi_{AB}) >1$. Easy to see that $n(\psi_{AB}) = 1 \implies$ product state as then can write $\psi_{AB} = \ket{i_A} \otimes \ket{j_B}$ as only one non-zero schmidt coefficent.

\subsection{Purification}
It is possible to convert a mixed state into a pure state by adding a purifying reference system $\mathbm{R}$ with Hilbert space $\mathbm{H}_R$, and defining a pure state $\ket{\psi_{AR}} \in \mathbm{H}_A \otimes \mathbm{H}_B$ such that:
$$
\rho_A = Tr_R \ket{\psi_{AR}}\bra{\psi_{AR}} = \sum_{i=1}\lambda_i^2 \ket{i_A}\bra{i_A}
$$
Given a $\rho_A$ we write its spectral decompistion (diagonlise it): 
$$
\rho_A = \sum^{d_A}_{i=1} p_i \ket{i_a} \bra{i_A}
$$
Define
$$
\ket{\psi_{AR}} = \sum_{i=1}^{d_A} \sqrt{p_i} \ket{i_A} \ket{i_R}
$$
then it is easy to check this statifies the relation above. More generally there is a canonical way of writing a purification:
$$
\ket{\psi_{AR}} = (\sqrt{\rho_A} \otimes I) \ket{\tilde \Omega} 
$$
for $\ket{\tilde \Omega} = \sqrt{d} \ket{\Omega}$ and $\ket{\Omega} = \frac{1}{\sqrt{d}} \sum_{i=1}^{d} \ket{i_A}\ket{i_R}$. Need to check that $\rho_A = Tr_R \ket{\psi_{AR}}\bra{\psi_{AR}} $
Usefulness of pure states:
$$
\rho = \sum \lamda_i \ket{i} \bra{i} \implies f(\rho) = \sum f(\lambda_i) \ket{i} \bra{i} \implies \sqrt{\rho} = \sum \sqrt{\lambda_i} \ket{i}\bra{i}
$$
\subsection{No-cloning theorem (N.C thm)}
There does not exist a universal quantum copier. You cannot make perfect copies of arbitary unknown quantum states. You can copy some states undersome conditions. \\
\textbf{Proof by contradiction}:\\
Assume there exists a universal quantum copier which takes arbitary states $\ket{\psi}$ or $\ket{\phi}$ and blank slate $\ket{s}$. Assume there exists U s.t.
$$
U(\ket{\psi}\ket{s}) = \ket{\psi}\ket{\psi}, U(\ket{\phi}\ket{s}) = \ket{\phi}\ket{\phi}
$$
Take inner product of LHS
$$
\bra{\psi} \bra{s} U^{\dagger} U \ket{\psi} \ket{s} = \bra{\psi} \bra{\psi} \ket{\phi} \ket{\phi}
$$
$$
\bra{\psi} \ket{\phi} \bra{s} \ket{s} = \bra{\psi}\ket{\phi}^2
$$
so cannot copy arbitary states can only copy orthogonal states with the same copier as must have $\bra{\psi}\ket{\phi} = 0$ (orthogonal) or $\bra{\psi}\ket{\phi} = 1$ (identical states).\\
\textbf{Second proof by contradiction}
Use qubits: $\psi = \alpha \ket{0} + \beta \ket{1}$, and $\ket{s} = \ket{0}$. Therefore assume that U exists such that:
$$
U\ket{\psi}\ket{0} = \ket{\psi}\ket{\psi} = \alpha^2 \ket{0} \ket{0} + \alpha \beta\ket{0} \ket{1} + \alpha \beta \ket{1} \ket{0} + \beta^2 \ket{1} \ket{1}
$$
$$
U\ket{0}\ket{0} = \ket{0}\ket{0}, U\ket{1}\ket{0} = \ket{1}\ket{1}
$$
So,
$$
U(\ket{\psi}\ket{0}) = U(\alpha \ket{0} + \beta \ket{1}) \ket{0} = \alpha \ket{0} \ket{0} + \beta \ket{1} \ket{1}
$$
So this is a contradiction unless $\alpha=1, \beta = 0$ or $\alpha =0, \beta =1$.\\\\
An implication of the no-cloning theorem is that superluminal communication is impossible.
\subsection{Maximally Entangled States}
$$
\ket{\psi_{AB}}, \lambda_i = \frac{1}{\sqrt{d}}, d = min(d_A, d_B)
$$
$$
\ket{\psi_{AB}} = \frac{1}{\sqrt{d}} \sum_{i=1}^d \ket{i_A} \ket{i_B} 
$$
Its reduced states are completely mixed states if $d_A = d_B = d$:
$$
\rho_A = \frac{1}{d} \sum \ket{i_A} \bra{i_A}, \rho_B = \frac{1}{d} \sum \ket{i_B}\bra{i_B}
$$
If $d_A < d_B$ then $\rho_A$ is a completely mixed state and $\rho_B$ is a completely mixed state on their supports:
$$
\rho_A = \frac{1}{d_A} \sum \ket{i_A} \bra{i_A}, \rho_B = \frac{1}{d_A} \sum^{d_A} \ket{i_B}\bra{i_B}
$$
\textbf{Properties}\\
$\ket{\psi_{AB}} = \mathrm{H}_A \otimes \mathrm{H}_B \approx \mathbb{C}^d \otimes \mathbb{C}^d$
These are two qudits. 
Fix the orthonormal basis on $\mathbb{C}^2$ of $\{\ket{i}\}^d_{i=1}$ and let:
$$
\ket{\Omega} = \frac{1}{\sqrt{d}} \sum^{d}_{i=1} \ket{i} \ket{i} 
$$
\textbf{Lemma 1}: $\forall A, B \in \mathfrak{B}(\mathbb{C}^d)$ we have $\bra{\Omega} A \otimes B \ket{\Omega} = Tr(A^T B)$ where T is the transposition in the chosen basis (schmidt basis of $\ket{\Omega}$\\\\
\textbf{Lemma 2}: Ricoche trick $ (A \otimes I) \ket{\Omega} = (I \otimes A^T) \ket{\Omega}$\\
Proof:
$$
A = \sum_{i=1}^d a_{jk} \ket{j} \bra{k}
$$
LHS of lemma 2:
$$
= \frac{1}{\sqrt{d}}\sum_i[(\sum_{jk} a_{jk} \ket{j} \bra{k} )\otimes I] \ket{i} \otimes \ketPi} = \frac{1}{\sqrt{d}}\sum_{ij} a_{ji} \ket{j}\ket{i}
$$
$$
A^T = \sum_{kj} \ket{j} \bra{k} 
$$
RHS of lemma 2:
$$
= \frac{1}{\sqrt{d}}\sum_{ij} \ket{i} \otimes a_{ij} \ket{j} =  \frac{1}{\sqrt{d}}\sum_{ij}  a_{ij} \ket{j}\ket{i}$$
Remember these lemmas we will use it over and over again.\\
\textbf{Implications of Lemma 1}\\
Given a state $\rho_A$ then the canonical purification is$\ket{\psi_{AB}} = \sqrt{d} (\sqrt{\rho_A} \otimes I) \ket{\Omega}$ as:
$$
\rho_A = Tr_B \ket{\psi_{AB}}\bra{\psi_{AB}} = Tr_B d (\sqrt{\rho_A} \otimes I) \ket{\Omega} \bra{\Omega}  (\sqrt{\rho_A} \otimes I) = Tr_B \sum_{ij} \sqrt{\rho_A} \ket{i} \bra{j} \sqrt{\rho_A} \otimes \ket{i} \bra{j} = \sum_i \sqrt{\rho_A} \ket{i} \bra{i} \sqrt{\rho_A} = I $$
Every biparitate state can be written:
$$
\ket{\psi_{AB}} = (I \otimes R) \ket{\Omega}
$$
for some operator R. Proof by construction:\\
$$
\ket{\psi_{AB}} = \sum \lambda_i \ket{i_A} \ket{i_B} \in \mathrm{H}_A \otimes \mathrm{H}_B
$$
Choose two isometries U, V s.t.
$$
U^{\dagger}U = V^{\dagger}V = I, U\ket{i} = \ket{i_A}, V\ket{i} = \ket{i_B}, D = \sum \lambda_k \ket{k} \bra{k}
$$
Let $R = \sqrt{d} V D U^T$ therefore:
$$
(I \otimes R) \ket{\Omega} = (I \otimes VDU^T) \ket{\Omega} = (I \otimes VD)(I \otimes U^T) \ket{\Omega} =^{\text{lemma 2}}  (U \otimes VD)\ket{\Omega}
$$
$$
(I \otimes R) \ket{\Omega} = \sum_i (U \otimes VD)\ket{i} \otimes \ket{i} = \sum_i \ket{i_A} \otimes V \sum_k \lambda_k \ket{k} \bra{k} \ket{i} =  \sum_i \ket{i_A} \otimes V \lambda_i \ket{i} =  \sum_i \lambda_i  \ket{i_A} \otimes \ket{i_B} 
$$
\textbf{Aside about Schmidt}\\
$\ket{\psi_{AB}} = \ket{\psi_A} \otimes \ket{\xi_B} \neq \sum_{i>1} \lambda_i \ket{i_A}\ket{i_B}$ as the schmidt coefficents are unique as they are the eigenvalues of $\rho_A$ and $\rho_B$, so the schmidt rank is unique.
\section{Time evolution of open quantum system}
Dynamics is given by a quantum operation (also called a quantum channel).\\
\textbf{Quantum Operation}: $\Lambda: \mathrm{D}(\mathrm{H}) \rightarrow \mathrm{D}(\mathrm{K})$ and is a completely positive, trace-preserving map (CPTP) map\\
- It enables a description of discrete state changes
$$
\Lambda \rho_{t=0} \rightarrow \rho'_{t>0} = \Lambda(\rho)
$$
$\Lambda$ is a superoperator and can map from operators in general $\mathrm{H}$ to other operators on $\mathrm{H}$: $\Lambda: \mathrm{B}(\mathrm{H}) \rightarrow \mathrm{B}(\mathrm{K})$.\\
\textbf{Properties of $\Lambda$}\\
- Linearity $\Lambda(p_1 \rho_1 + p_2 \rho_2) = p_1 \Lambda (\rho_1) + p_2 \Lambda(\rho_2)$\\
- Trace preserving: $Tr \Lambda(\rho) = Tr \rho = 1$, $\rho \in \mathrm{D}(\mathrm{H})$ this corresponds to the conservation of probablity.\\
- Positivity [positive(-semidefiniteness) preserving] $\rho \geq 0 \implies \Lambda(\rho) \geq 0$\\
- Completely positive (CP):
$$
(\Lambda \otimes id_B): \mathrm{D}(\mathrm{H}_A)\otimes\mathrm{B}(\mathrm{H}_B) \rightarrow \mathrm{D}(\mathrm{K})\otimes\mathrm{B}(\mathrm{H}_B)
$$
is completely positive if $(\Lambda \otimes id_B)$ is positive for all $B$:
$$
(\Lambda \otimes id_B)\rho_{AB} \geq 0
$$
\textbf{Further consideration of completely positiveness (CP)}\\
$$
\mathrm{H} = \mathbb{C}^m, \mathrm{K} = \mathbb{C}^n
$$
use notation: $M_m$ is set of complex $m \times m$ matrices, $M^+_m$ is set of positive semi definite complex $m \times m$ matrices, $\mathrm{B}(\mathbb{C}^n) = M_m$, $\mathrm{D}(\mathrm{H}) = \{ \rho \in M^+_m , Tr \rho = 1\}$. \\\\
A linear map $\Lambda: M_m \rightarrow M_n$ is positive if $\Lambda(A) \in M^+_n $ if $A \in M^+_m$.\\\\
k-positive for any $k \geq 1$ if $(\Lambda \otimes id_k)$ is positive\\\\
Is completely positive if it is k-positive for all positive integres k\\
\subsubsection{Necessary and sufficent condtion for complete positivity}
A linear map $\Lambda: \mathrm{B}(\mathrm{H}) \rightarrow \mathrm{B}(\mathrm{K})$ with $\mathrm{H} = \mathbb{C}^d$ and  $\mathrm{K} = \mathbb{C}^{d'}$  is completely positive iff
$$
(\Lambda \otimes id_d)\ket{\Omega}\bra{\Omega} \geq 0
$$
Proof:
If it is completely positive then it is obvious as it is a completely positive operator acting on a positive state so it will be positive. Now proof opposite direction:\\\\
Consider an arbitary $k \geq 1$ and a bipartite state $\rho \in M_d \otimes M_k$ with spectral decomposition: $\rho = \sum_{i=1}^d \lambda_i \ket{\psi_i} \bra{\psi_i}$.
$$
(\Lambda \otimes id_k)\rho \geq 0 \iff \sum \lambda_i (\Lambda \otimes id_k)\ket{\psi_i}\bra{\psi_i} \geq 0 \iff (\Lambda \otimes id_k)\ket{\psi_i}\bra{\psi_i} \geq 0 \forall i
$$
second iff holds as $\lambda_i \geq 0$. As any bipartite state can be written $\ket{\psi} = (I \otimes R) \ket{\Omega}$. Since $\ket{\Omega_i} \in \mathbb{C}^d \otimes \mathbb{C}^k$ there exists $R_i$ s.t. $\ket{\psi_i} = (I \otimes R_i) \ket{\Omega}$. So the above can be written as:
$$
(\Lambda \otimes id_k)(I \otimes R_i) \ket{\Omega} \bra{\Omega} (I_d \otimes R^{\dagger}_i) \geq 0
$$
Note that $R_i \in \mathcal{B}(\mathbb{C}^d, \mathbb{C}^d$). Define a superoperator $Q_i: \mathcal{B}(\mathbb{C}^d) \rightarrow \mathcal{B}(\mathbb{C}^k)$ such that $Q_i(.) R_i(.)R_i^{\dagger}$. So:
$$
(\Lambda \otimes id_k)(I \otimes R_i) \ket{\Omega} \bra{\Omega} (I_d \otimes R^{\dagger}_i) = (\Lambda \otimes id_k)(id_d \otimes Q_i) \ket{\Omega} \bra{\Omega}= (id_{d'} \otimes Q_i) (\Lambda \otimes id_d)(\ket{\Omega} \bra{\Omega} \geq 0
$$
$$
(id_{d'} \otimes R_i) (\Lambda \otimes id_d)(\ket{\Omega} \bra{\Omega} (id_{d'} \otimes R^{\dagger}_i) \geq 0
$$
let $A= (id_{d'} \otimes R_i) $ and $B = (\Lambda \otimes id_d)\ket{\Omega} \bra{\Omega} $
as
$$
B \geq 0 \implies ABA^{\dagger} \geq 0$$
$$(\Lambda \otimes id_d)\ket{\Omega} \bra{\Omega} \geq 0 \implies (\Lambda \otimes id_d)\rho \geq 0$$
\end{document}

